{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookair/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from chainer import Variable, optimizers\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20005, 60)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('article_train_clean.csv',index_col=False)\n",
    "print(data.shape)\n",
    "data.rename(columns={'Unnamed: 0':'article_id','shared':'n_shares',}, inplace=True)\n",
    "#Set article_id as index of the data frame (its values are used as labels for rows)\n",
    "data.set_index('article_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20005\n"
     ]
    }
   ],
   "source": [
    "q_col = pd.read_excel('query_column.xlsx')\n",
    "q_col = q_col['q_id'].tolist()\n",
    "print(len(q_col))\n",
    "data.insert(1, 'q_id',q_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_shares    1100.000000\n",
      "q_id           2.000000\n",
      "c1             0.333333\n",
      "Name: 46, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#making sure data is loaded correctly\n",
    "#qid_1(1-24)\n",
    "#qid_2(25-46)--last n_shares = 1100\n",
    "#qid_3(47-..)--first n_shares = 776\n",
    "art_id = 46\n",
    "print(data.loc[art_id , ['n_shares', 'q_id','c1'] ])\n",
    "nq = data['q_id'].nunique()  # 360 total queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "            n_shares  q_id        c1        c2        c3       c4        c5  \\\n",
      "article_id                                                                    \n",
      "25             16900     2  0.571429  0.098655  0.000689  0.00096  0.000907   \n",
      "26              9500     2  0.571429  0.089686  0.000704  0.00096  0.001105   \n",
      "27              1600     2  0.428571  0.000000  0.000000  0.00000  0.000000   \n",
      "28              1900     2  0.428571  0.041893  0.000871  0.00096  0.001301   \n",
      "29              1100     2  0.428571  0.041185  0.000762  0.00096  0.001058   \n",
      "30              1400     2  0.285714  0.025372  0.000857  0.00096  0.001037   \n",
      "31              1200     2  0.571429  0.054402  0.000703  0.00096  0.000998   \n",
      "32              1600     2  0.523810  0.071159  0.000539  0.00096  0.000712   \n",
      "33              1700     2  0.428571  0.053576  0.000932  0.00096  0.001160   \n",
      "34             15000     2  0.285714  0.073283  0.000749  0.00096  0.001097   \n",
      "35              1300     2  0.238095  0.058768  0.000754  0.00096  0.001075   \n",
      "36              5500     2  0.285714  0.162615  0.000626  0.00096  0.000936   \n",
      "37              3900     2  0.476190  0.049681  0.000725  0.00096  0.001053   \n",
      "38              2900     2  0.380952  0.059948  0.000748  0.00096  0.001059   \n",
      "39              1100     2  0.476190  0.122610  0.000608  0.00096  0.000946   \n",
      "40              3400     2  0.380952  0.112344  0.000654  0.00096  0.001045   \n",
      "41              7900     2  0.428571  0.029030  0.000669  0.00096  0.000785   \n",
      "42              1800     2  0.333333  0.069153  0.000828  0.00096  0.001186   \n",
      "43             11700     2  0.619048  0.044725  0.000766  0.00096  0.001086   \n",
      "44              4000     2  0.333333  0.153292  0.000580  0.00096  0.000937   \n",
      "45             27500     2  0.380952  0.057706  0.000712  0.00096  0.000997   \n",
      "46              1100     2  0.333333  0.055464  0.000716  0.00096  0.000983   \n",
      "\n",
      "                  c6        c7        c8    ...          c49       c50  c51  \\\n",
      "article_id                                  ...                               \n",
      "25          0.032895  0.017241  0.062500    ...     0.372297  0.100000  1.0   \n",
      "26          0.013158  0.017241  0.023438    ...     0.352244  0.100000  0.8   \n",
      "27          0.000000  0.000000  0.132812    ...     0.000000  0.000000  0.0   \n",
      "28          0.016447  0.017241  0.007812    ...     0.396296  0.050000  0.8   \n",
      "29          0.006579  0.008621  0.007812    ...     0.201010  0.033333  0.4   \n",
      "30          0.062500  0.025862  0.109375    ...     0.600000  0.200000  1.0   \n",
      "31          0.026316  0.043103  0.007812    ...     0.271170  0.033333  0.5   \n",
      "32          0.009868  0.008621  0.117188    ...     0.374558  0.136364  0.7   \n",
      "33          0.075658  0.034483  0.140625    ...     0.419215  0.100000  1.0   \n",
      "34          0.049342  0.008621  0.101562    ...     0.469241  0.033333  1.0   \n",
      "35          0.036184  0.000000  0.007812    ...     0.372174  0.100000  0.7   \n",
      "36          0.088816  0.008621  0.101562    ...     0.312641  0.050000  1.0   \n",
      "37          0.026316  0.043103  0.015625    ...     0.336428  0.062500  0.6   \n",
      "38          0.046053  0.086207  0.023438    ...     0.370734  0.100000  0.7   \n",
      "39          0.029605  0.077586  0.015625    ...     0.453259  0.100000  1.0   \n",
      "40          0.042763  0.017241  0.023438    ...     0.328568  0.033333  1.0   \n",
      "41          0.085526  0.017241  0.179688    ...     0.429762  0.166667  1.0   \n",
      "42          0.023026  0.025862  0.023438    ...     0.252362  0.033333  0.5   \n",
      "43          0.029605  0.060345  0.015625    ...     0.262729  0.100000  0.7   \n",
      "44          0.052632  0.000000  0.007812    ...     0.351237  0.033333  0.8   \n",
      "45          0.082237  0.008621  0.093750    ...     0.405565  0.100000  0.8   \n",
      "46          0.009868  0.025862  0.007812    ...     0.000000  0.000000  0.0   \n",
      "\n",
      "                 c52       c53       c54       c55       c56       c57  \\\n",
      "article_id                                                               \n",
      "25          0.854891  0.400000  0.987500  0.316667  0.537500  0.366666   \n",
      "26          0.782738  0.400000  0.950000  0.500000  0.568182  0.000000   \n",
      "27          1.000000  1.000000  1.000000  0.000000  0.500000  1.000000   \n",
      "28          0.833333  0.833333  0.833333  0.600000  0.750000  0.200000   \n",
      "29          0.550983  0.200000  0.925000  0.000000  0.500000  1.000000   \n",
      "30          0.721429  0.500000  0.875000  0.000000  0.500000  1.000000   \n",
      "31          0.797685  0.500000  0.900000  0.300000  0.450000  0.400000   \n",
      "32          0.747619  0.500000  0.900000  0.000000  0.500000  1.000000   \n",
      "33          0.710317  0.200000  0.950000  0.550000  0.568750  0.100000   \n",
      "34          0.621270  0.300000  0.900000  0.650000  0.250000  0.300000   \n",
      "35          0.822222  0.683333  0.950000  0.125000  0.500000  0.750000   \n",
      "36          0.638571  0.400000  0.850000  0.900000  0.700000  0.800000   \n",
      "37          0.875000  0.875000  0.875000  0.125000  0.500000  0.750000   \n",
      "38          0.728704  0.300000  0.950000  0.575000  0.425000  0.150000   \n",
      "39          0.721681  0.000000  0.950000  0.300000  0.550000  0.400000   \n",
      "40          0.816667  0.700000  0.900000  0.000000  0.500000  1.000000   \n",
      "41          0.843750  0.812500  0.875000  1.000000  0.750000  1.000000   \n",
      "42          0.780556  0.600000  0.900000  0.000000  0.500000  1.000000   \n",
      "43          0.671465  0.500000  0.875000  1.000000  0.250000  1.000000   \n",
      "44          0.818519  0.600000  0.950000  0.650000  0.500000  0.300000   \n",
      "45          0.719028  0.500000  0.844444  0.000000  0.500000  1.000000   \n",
      "46          0.797222  0.700000  0.875000  0.000000  0.500000  1.000000   \n",
      "\n",
      "                 c58  \n",
      "article_id            \n",
      "25          0.075000  \n",
      "26          0.136364  \n",
      "27          0.000000  \n",
      "28          0.500000  \n",
      "29          0.000000  \n",
      "30          0.000000  \n",
      "31          0.100000  \n",
      "32          0.000000  \n",
      "33          0.137500  \n",
      "34          0.500000  \n",
      "35          0.000000  \n",
      "36          0.400000  \n",
      "37          0.000000  \n",
      "38          0.150000  \n",
      "39          0.100000  \n",
      "40          0.000000  \n",
      "41          0.500000  \n",
      "42          0.000000  \n",
      "43          0.500000  \n",
      "44          0.000000  \n",
      "45          0.000000  \n",
      "46          0.000000  \n",
      "\n",
      "[22 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "print(nq) #Number of avialble queries in the dataset\n",
    "dq = data[data['q_id']==2] \n",
    "dq = dq.iloc[:,:]\n",
    "print(dq) #printing second query for data demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookair/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# preparing the testing and training data, here I use 80% of the queries for training and reserve 20% for testing\n",
    "# then the training and testing labels are separated from the training and testing features, labels are\n",
    "# basically the values we need to predict and features are the values of the feature vector that describe \n",
    "#each record\n",
    "nt_tst = 0.2*nq # 20% of the number of queries are used as test data (72)\n",
    "nt_train = 0.8*nq # 80% of the number of queires are for training (288)\n",
    "X_test = data.query('1 <= q_id <= 72')\n",
    "X_train = data.query('73 <= q_id <= 288')\n",
    "y_test =  X_test.loc[:,['n_shares','q_id']]\n",
    "X_test.drop([\"n_shares\"], axis = 1, inplace = True)\n",
    "y_train =  X_train.loc[:,['n_shares','q_id']]\n",
    "X_train.drop([\"n_shares\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import Variable, optimizers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from chainer import Chain\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "class MLP(Chain):\n",
    "   \n",
    "    #n_in: the number of features  in the feature vector  \n",
    "    #n_hidden: number of hidden layers passed to the model\n",
    "    def __init__(self, n_in, n_hidden):\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(n_in, n_hidden),\n",
    "            l2=L.Linear(n_hidden, n_hidden),\n",
    "            l3=L.Linear(n_hidden, 1)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "\n",
    "class RankNet(Chain):\n",
    "\n",
    "    def __init__(self, predictor):\n",
    "        super(RankNet, self).__init__(predictor=predictor)\n",
    "\n",
    "    # the model works in a pairwise approach where each pair of articles are grouped together and the model\n",
    "    # assigns initla score for each of them using the random inital weights, these scores are then \n",
    "    # mapped to a sigmoid function (F.log(1 + F.exp(-s_diff))) which is a continous function suitable for \n",
    "    # optimisation used for measuring th eporbability of ranking an article above the other based on the scores\n",
    "    # that the model predicted, then we penalize the output of this predicted probability from the actual\n",
    "    # ranking probability (1 if A>B, 0 if A < B, 0.5 if A=B) that we know based on the labels of the training data\n",
    "    # this deviation from the actual porbability is measured using a cross entropy cost function\n",
    "    # More detailed information about the model are found in the attached report\n",
    "    def __call__(self, x_i, x_j, t_i, t_j):\n",
    "        s_i = self.predictor(x_i)\n",
    "        s_j = self.predictor(x_j)\n",
    "        s_diff = s_i - s_j\n",
    "        if t_i.data > t_j.data:\n",
    "            S_ij = 1\n",
    "        elif t_i.data < t_j.data:\n",
    "            S_ij = -1\n",
    "        else:\n",
    "            S_ij = 0\n",
    "        self.loss = (1 - S_ij) * s_diff / 2. + F.log(1 + F.exp(-s_diff))\n",
    "        return self.loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the performance measurement factor, NDCG is used for measuring the perofmance of information \n",
    "# retreival models by comparing the ouput ranking with the actualr ranking, the way it works is by \n",
    "# having more peanlization on wrong rankings at the top and less weight on the wrong ranking at the bottom\n",
    "def ndcg(y_true, y_score, k=10):\n",
    "    y_true = y_true.ravel()\n",
    "    y_score = y_score.ravel() \n",
    "    y_true_sorted = sorted(y_true, reverse=True)\n",
    "    ideal_dcg = 0\n",
    "    for i in range(k):\n",
    "        ideal_dcg += (y_true_sorted[i]) / np.log2(i + 2)\n",
    "    dcg = 0\n",
    "    argsort_indices = np.argsort(y_score)[::-1]\n",
    "    for i in range(k):\n",
    "        dcg += (y_true[argsort_indices[i]]) / np.log2(i + 2)\n",
    "    ndcg = dcg / ideal_dcg\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            q_id        c1        c2        c3       c4\n",
      "article_id                                             \n",
      "3864          73  0.380952  0.115294  0.000575  0.00096\n",
      "3865          73  0.238095  0.028558  0.000901  0.00096\n",
      "3866          73  0.428571  0.105499  0.000681  0.00096\n",
      "3867          73  0.333333  0.104437  0.000693  0.00096\n",
      "3868          73  0.380952  0.013335  0.001073  0.00096\n",
      "3869          73  0.238095  0.025844  0.000936  0.00096\n",
      "3870          73  0.476190  0.050153  0.000792  0.00096\n",
      "3871          73  0.380952  0.056998  0.000786  0.00096\n",
      "3872          73  0.380952  0.052514  0.000813  0.00096\n",
      "3873          73  0.333333  0.025018  0.000912  0.00096\n",
      "3874          73  0.190476  0.096413  0.000632  0.00096\n",
      "3875          73  0.285714  0.084494  0.000683  0.00096\n",
      "3876          73  0.428571  0.108449  0.000625  0.00096\n",
      "3877          73  0.428571  0.080245  0.000693  0.00096\n",
      "3878          73  0.428571  0.100425  0.000650  0.00096\n",
      "3879          73  0.238095  0.065494  0.000757  0.00096\n",
      "3880          73  0.380952  0.050979  0.000690  0.00096\n",
      "3881          73  0.428571  0.138187  0.000557  0.00096\n",
      "3882          73  0.380952  0.014751  0.001096  0.00096\n",
      "3883          73  0.333333  0.180316  0.000525  0.00096\n",
      "3884          73  0.380952  0.045551  0.000719  0.00096\n",
      "3885          73  0.476190  0.031508  0.000775  0.00096\n",
      "3886          73  0.333333  0.012981  0.001165  0.00096\n",
      "3887          73  0.380952  0.018409  0.000884  0.00096\n",
      "3888          73  0.571429  0.081780  0.000737  0.00096\n",
      "3889          73  0.380952  0.026080  0.000915  0.00096\n",
      "3890          73  0.238095  0.115648  0.000676  0.00096\n",
      "            n_shares  q_id\n",
      "article_id                \n",
      "3864            1300    73\n",
      "3865            1500    73\n",
      "3866            4700    73\n",
      "3867            2000    73\n",
      "3868            2200    73\n",
      "3869            1400    73\n",
      "3870            4600    73\n",
      "3871           65300    73\n",
      "3872            2900    73\n",
      "3873            1700    73\n",
      "3874            1400    73\n",
      "3875            1500    73\n",
      "3876            2100    73\n",
      "3877            1000    73\n",
      "3878            1400    73\n",
      "3879            1400    73\n",
      "3880            2200    73\n",
      "3881            3300    73\n",
      "3882            3600    73\n",
      "3883            2200    73\n",
      "3884            1300    73\n",
      "3885            2000    73\n",
      "3886            1600    73\n",
      "3887           13400    73\n",
      "3888            4500    73\n",
      "3889           10300    73\n",
      "3890            4400    73\n"
     ]
    }
   ],
   "source": [
    "# visualizing query 37 records \n",
    "dtmp = X_train[X_train['q_id']==73]\n",
    "print(dtmp.iloc[:,0:5])\n",
    "dtmp = y_train[y_train['q_id']==73]\n",
    "print(dtmp.iloc[:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________iteration_____________\n",
      "0\n",
      "______________train_____________\n",
      "train query\n",
      "73\n",
      "train_ndcg\n",
      "0.5926594353696825\n",
      "train query\n",
      "74\n",
      "train_ndcg\n",
      "0.6453661679467113\n",
      "train query\n",
      "75\n",
      "train_ndcg\n",
      "0.2275615973439507\n",
      "train query\n",
      "76\n",
      "train_ndcg\n",
      "0.6307773743003677\n",
      "train query\n",
      "77\n",
      "train_ndcg\n",
      "0.4065165318490817\n",
      "train query\n",
      "78\n",
      "train_ndcg\n",
      "0.1430822334687798\n",
      "train query\n",
      "79\n",
      "train_ndcg\n",
      "0.7255584150894336\n",
      "train query\n",
      "80\n",
      "train_ndcg\n",
      "0.1367877076751512\n",
      "train query\n",
      "81\n",
      "train_ndcg\n",
      "0.2251223783473866\n",
      "train query\n",
      "82\n",
      "train_ndcg\n",
      "0.8354526957709834\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a175e40faf79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_j\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m#measuring loss (cost) function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzerograds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#zero out gradients because backward propogation accumlates them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad, enable_double_backprop, loss_scale)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \"\"\"\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enable_backprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_double_backprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_backward_main\u001b[0;34m(self, retain_grad, loss_scale)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                     y._set_grad_var_if_available(\n\u001b[0;32m-> 1069\u001b[0;31m                         gy if retain_grad else None)\n\u001b[0m\u001b[1;32m   1070\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_grad\u001b[0m  \u001b[0;31m# to reduce memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_set_grad_var_if_available\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_grad_var_if_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "n_dim = 58\n",
    "n_iter = 10\n",
    "n_hidden = 5\n",
    "loss_step = 2\n",
    "N_train = np.shape(X_train)[0] \n",
    "model = RankNet(MLP(n_dim, n_hidden))\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "N_train = np.shape(X_train)[0]\n",
    "train_ndcgs = []\n",
    "test_ndcgs = []\n",
    "\n",
    "for step in range(n_iter):\n",
    "    print(\"______________iteration_____________\")\n",
    "    print(step)\n",
    "    print(\"______________train_____________\")\n",
    "    train_ndcg = 0\n",
    "    test_ndcg = 0\n",
    "    for qtmp in range(73,277):                                  #training over our training queries\n",
    "        qx_train = X_train[X_train['q_id']==qtmp]   \n",
    "        qx_train.drop([\"q_id\"], axis = 1, inplace = True)\n",
    "        qx_train = np.float32(qx_train.values)                  #preparing traiing feature vectors\n",
    "        n_q_items = np.shape(qx_train)[0]\n",
    "        qy_train = y_train[y_train['q_id']==qtmp]\n",
    "        qy_train.drop([\"q_id\"], axis = 1, inplace = True)\n",
    "        qy_train = np.float32(qy_train.values)                  #preparing training labels\n",
    "        for itmp in range(0,n_q_items):\n",
    "             for jtmp in range(itmp+1,n_q_items):\n",
    "                if itmp != jtmp:\n",
    "                    x_i = Variable(qx_train[itmp].reshape(1, -1))\n",
    "                    x_j = Variable(qx_train[jtmp].reshape(1, -1)) \n",
    "                    y_i = Variable(qy_train[itmp])\n",
    "                    y_j = Variable(qy_train[jtmp])\n",
    "                    loss = model(x_i, x_j, y_i, y_j)           #measuring loss (cost) function\n",
    "                    model.zerograds()   #zero out gradients because backward propogation accumlates them\n",
    "                    loss.backward()\n",
    "                    optimizer.update()\n",
    "        train_score = model.predictor(Variable(qx_train))\n",
    "        tmp = ndcg(qy_train, train_score.data)\n",
    "        train_ndcg = train_ndcg+ tmp\n",
    "        print(\"train query\")\n",
    "        print(qtmp)\n",
    "        print(\"train_ndcg\")\n",
    "        print(tmp)\n",
    "    print(\"______________test_____________\")    \n",
    "    for qtst in range(1,71):\n",
    "        qx_test = X_test[X_test['q_id']==qtst]\n",
    "        qx_test.drop([\"q_id\"], axis = 1, inplace = True)\n",
    "        n_q_items = np.shape(qx_test)[0]\n",
    "        qy_test = y_test[y_test['q_id']==qtst]\n",
    "        qy_test.drop([\"q_id\"], axis = 1, inplace = True)\n",
    "        test_score = model.predictor(Variable(np.float32(qx_test.values)))\n",
    "        tmp = ndcg(np.float32(qy_test.values), test_score.data)\n",
    "        test_ndcg = test_ndcg + tmp\n",
    "        print(\"test query\")\n",
    "        print(qtst)\n",
    "        print(\"test_ndcg\")\n",
    "        print(tmp)\n",
    "if (step + 1) % loss_step == 0:\n",
    "    train_ndcgs.append(train_ndcg/216)\n",
    "    test_ndcgs.append(test_ndcg/72)\n",
    "    print(\"step: {}\".format(step + 1))\n",
    "    print(\"NDCG@10 | train: {}, test: {}\".format(\n",
    "        train_ndcg/216, test_ndcg/72))\n",
    "\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "plt.plot(train_ndcgs, label=\"Train\")\n",
    "plt.plot(test_ndcgs, label=\"Test\")\n",
    "xx = np.linspace(0, n_iter / loss_step, num=n_iter / loss_step + 1)\n",
    "labels = np.arange(loss_step, n_iter + 1, loss_step)\n",
    "plt.xticks(xx, labels, rotation=45)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"NDCG@10\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
